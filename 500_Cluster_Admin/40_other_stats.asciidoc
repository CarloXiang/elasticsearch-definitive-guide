
=== 集群统计值

`集群统计值` API 提供和 `节点统计值` 相似的输出。((("clusters", "administration", "Cluster Stats API")))但有一个重要区别：节点统计值显示的是每个节点上的统计值，而 `集群统计值` 显示的是单个指标上，所有节点的总和值。

这里面提供一些很值得一看的统计值。你可以看到比如说，你整个集群用了 50% 的 heap，或者说过滤器缓存的驱逐情况不严重。这个接口的主要用途是提供一个比 `集群健康` 更详细、但又没 `节点统计值` 那么详细的快速概览。对于非常大的集群来说也很有用，因为那时候 `节点统计值` 的输出已经非常难读懂了。

这个 API 可以想下面这样调用：

[source,js]
----
GET _cluster/stats
----

=== 索引统计值

到目前为止，我们看到的都是 _以节点为中心的_ 统计值：((("indices", "index statistics")))((("clusters", "administration", "index stats")))这个节点有多少内存？用了多少 CPU？正在服务多少个搜索？

有时候从 _以索引为中心_ 的角度看统计值也很有用：_这个索引_ 收到了多少个搜索请求？_那个索引_ 花了多少时间在获取文档？

要做到这点，选择你感兴趣的索引（或者多个索引），然后执行一个索引级别的 `统计` API：

[source,js]
----
GET my_index/_stats <1>

GET my_index,another_index/_stats <2>

GET _all/_stats <3>
----
<1> `my_index` 索引的统计值。
<2> 请求多个索引的统计值，用逗号分隔索引名即可。
<3> 通过特定的 `_all` 索引名请求全部索引的统计值。

返回的统计值和 `节点统计值` 的输出很相似：`search` `fetch` `get` `index` `bulk` `segment counts` 等等。

索引为中心的统计值在有些时候很有用，比如定义或验证集群中的 _热_ 索引，查找部分索引比其他更快或者更慢的原因。

实践中，节点为中心的统计值还是更有用些。整个节点碰到了瓶颈，而不是独立的索引。因为索引一般是分布在多个节点上的，这导致索引为中心的统计值通常不是很有用，因为它们是从不同环境不同物理设备上汇聚的数据。

索引为中心的统计值作为一个有用的工具可以保留在你的技能表里，但是通常它不会是第一个用上的工具。

=== 等待中的任务

有一些任务是只能由主节点处理的，比如创建一个新((("clusters", "administration", "Pending Tasks API")))索引或者在集群中转移分片。因为一个集群只能有一个主节点，所以只有这一个节点可以处理集群级别的元数据变动。在 99.999% 的时间里，这不会是什么问题。元数据变动的队列常年都是零。

在一些 _罕见的_ 集群里，元数据变更的次数比主节点能处理的还快。这会导致等待中的操作累积成队列。

`等待中的任务` API ((("Pending Tasks API")))会展现给你在队列中有什么（如果有的话）集群级别的元数据变更在等待：

[source,js]
----
GET _cluster/pending_tasks
----

通常，响应都是像这样的：

[source,js]
----
{
   "tasks": []
}
----

这意味着没有等待中的任务。如果你有一个罕见的集群在主节点出现瓶颈了，你的等待中任务列表可能会像这样：

[source,js]
----
{
   "tasks": [
      {
         "insert_order": 101,
         "priority": "URGENT",
         "source": "create-index [foo_9], cause [api]",
         "time_in_queue_millis": 86,
         "time_in_queue": "86ms"
      },
      {
         "insert_order": 46,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][1], node[tMTocMvQQgGCkj7QDHl3OA], [P], 
         s[INITIALIZING]), reason [after recovery from gateway]",
         "time_in_queue_millis": 842,
         "time_in_queue": "842ms"
      },
      {
         "insert_order": 45,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][0], node[tMTocMvQQgGCkj7QDHl3OA], [P], 
         s[INITIALIZING]), reason [after recovery from gateway]",
         "time_in_queue_millis": 858,
         "time_in_queue": "858ms"
      }
  ]
}
----

你可以看到任务都标记了优先级（比如说 `URGENT` 比 `HIGH` 要更早处理），任务插入的次序，操作进入队列多久，以及操作打算处理什么。在上面的示例中，有一个 `创建索引` 操作和两个 `启动分片` 操作在等待。

.什么时候我该担心等待中的任务？
****
就像曾经提过的，主节点很少会成为集群的瓶颈。唯一的可能就是集群状态非常大 _而且_ 频繁更新。

比如，如果你允许客户任意创建动态字段，而且每天每个客户都有一个独立索引，你的集群状态会变得非常大。集群状态包括（但不限于）所有索引的列表，他们的类型，以及每个索引的字段。

所以如果你有 100000 个客户，然后每个客户平均有 1000 个字段，而且数据有 90 天的保留期——这就是九十亿个字段需要保存在集群状态里。不管什么时候这个发生变化，所有的节点都需要被通知到。

主节点必须处理这些变动，这需要不一般的 CPU 开销，加上推送更新的集群状态到所有节点的网络开销。

这就是可能可以开始看到集群状态操作队列上涨的集群。没有什么简单办法可以解决这个问题。不过你有三个选择：

- 用一个更强大的主节点。不幸的是，垂直扩展只是拖延这种必然而已。
- 通过某些方式限定文档的动态性质，以此限制集群状态的大小。
- 到达某个阈值后，组件另一个集群。
****

=== cat API

如果你经常在命令行环境下工作，`cat` API 对你会非常有用。((("Cat API")))((("clusters", "administration", "Cat API")))用 Linux 的 `cat` 命令命名，这些 API 也就设计成像 *nix 命令行工具一样工作了。

他们提供的统计值和前面已经讨论过的 API（健康、`节点统计值`, 等等）是一样的。但是输出以表格形式提供，而不是 JSON。对于系统管理员这是 _非常_ 方便的，你只是想浏览一遍你的集群，找出来内存使用率偏高的节点而已。

通过 `cat` 终端发送简单的 GET 请求会列出所有可用 API：

[source,bash]
----
GET /_cat

=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
----

很多 API 你看起来都很熟悉了（对，顶上还有一只猫:)）。让我们看看查看健康 API：

[source,bash]
----
GET /_cat/health

1408723713 12:08:33 elasticsearch_zach yellow 1 1 114 114 0 0 114 
----

首先你会注意到响应是表格格式的纯文本，不是 JSON。其次你会注意到默认没有各列的表头。这都是模拟 *nix工具设计的，因为你一旦对输出很熟悉了，你就再也不想看表头了。

要开启表头，添加 `?v` 参数：

[source,bash]
----
GET /_cat/health?v

epoch   time    cluster status node.total node.data shards pri relo init  
1408[..] 12[..] el[..]  1         1         114 114    0    0     114 
unassign
----

嗯，好多了。我们现在看到时间戳、集群名称、状态、集群内的节点数量等等——所有的节点都需要被通知到信息和 `集群健康` API 的都一样。

让我们再看看 `cat` API 里的 `节点统计值` ：

[source,bash]
----
GET /_cat/nodes?v

host         ip            heap.percent ram.percent load node.role master name 
zacharys-air 192.168.1.131           45          72 1.85 d         *      Zach 
----

我们看到集群里节点的一些统计值，不过输出比起完整的 `节点统计值` 输出是非常的基础。你可以包含更多的指标，不过比起查阅文档，让我们直接问 `cat` API 哪些可用吧。

你可以通过对任意 API 添加 `?help` 参数做到这点：

[source,bash]
----
GET /_cat/nodes?help

id               | id,nodeId               | unique node id                          
pid              | p                       | process id                              
host             | h                       | host name                               
ip               | i                       | ip address                              
port             | po                      | bound transport port                    
version          | v                       | es version                              
build            | b                       | es build hash                           
jdk              | j                       | jdk version                             
disk.avail       | d,disk,diskAvail        | available disk space                    
heap.percent     | hp,heapPercent          | used heap ratio                         
heap.max         | hm,heapMax              | max configured heap                     
ram.percent      | rp,ramPercent           | used machine memory ratio               
ram.max          | rm,ramMax               | total machine memory                    
load             | l                       | most recent load avg                    
uptime           | u                       | node uptime                             
node.role        | r,role,dc,nodeRole      | d:data node, c:client node              
master           | m                       | m:master-eligible, *:current master  
...
...
----
（注意这个输出为了页面简洁被截断了）。

第一列显示完整的名称，第二轮显示简写，第三列提供这个参数的概述。现在我们知道一些列名了，我们可以用 `?h` 参数来显式查询这些：

[source,bash]
----
GET /_cat/nodes?v&h=ip,port,heapPercent,heapMax

ip            port heapPercent heapMax 
192.168.1.131 9300          53 990.7mb 
----

因为 `cat` API 试图像 *nix 工具一样工作，你可以把输出管道输出给其他工具，比如 `sort` 、`grep` 或者 `awk` 。比如我们可以用如下命令找出我们集群中最大的索引：

[source,bash]
----
% curl 'localhost:9200/_cat/indices?bytes=b' | sort -rnk8

yellow test_names         5 1 3476004 0 376324705 376324705 
yellow .marvel-2014.08.19 1 1  263878 0 160777194 160777194 
yellow .marvel-2014.08.15 1 1  234482 0 143020770 143020770 
yellow .marvel-2014.08.09 1 1  222532 0 138177271 138177271 
yellow .marvel-2014.08.18 1 1  225921 0 138116185 138116185 
yellow .marvel-2014.07.26 1 1  173423 0 132031505 132031505 
yellow .marvel-2014.08.21 1 1  219857 0 128414798 128414798 
yellow .marvel-2014.07.27 1 1   75202 0  56320862  56320862 
yellow wavelet            5 1    5979 0  54815185  54815185 
yellow .marvel-2014.07.28 1 1   57483 0  43006141  43006141 
yellow .marvel-2014.07.21 1 1   31134 0  27558507  27558507 
yellow .marvel-2014.08.01 1 1   41100 0  27000476  27000476 
yellow kibana-int         5 1       2 0     17791     17791 
yellow t                  5 1       7 0     15280     15280 
yellow website            5 1      12 0     12631     12631 
yellow agg_analysis       5 1       5 0      5804      5804 
yellow v2                 5 1       2 0      5410      5410 
yellow v1                 5 1       2 0      5367      5367 
yellow bank               1 1      16 0      4303      4303 
yellow v                  5 1       1 0      2954      2954 
yellow p                  5 1       2 0      2939      2939 
yellow b0001_072320141238 5 1       1 0      2923      2923 
yellow ipaddr             5 1       1 0      2917      2917 
yellow v2a                5 1       1 0      2895      2895 
yellow movies             5 1       1 0      2738      2738 
yellow cars               5 1       0 0      1249      1249 
yellow wavelet2           5 1       0 0       615       615 
----

通过 `?bytes=b` ，我们关闭了人类可读的数字格式化，强制他们以字节数输出。这个输出随后管道传递给 `sort` ，让我们的索引以大小（第八列）排序。

不幸的是，你会注意到 Marvel 索引也列在结果里，我们目前并不真的在意这部分索引。让我们把输出管道传递给 `grep` 移除提到 Marvel 的数据：

[source,bash]
----
% curl 'localhost:9200/_cat/indices?bytes=b' | sort -rnk8 | grep -v marvel

yellow test_names         5 1 3476004 0 376324705 376324705 
yellow wavelet            5 1    5979 0  54815185  54815185 
yellow kibana-int         5 1       2 0     17791     17791 
yellow t                  5 1       7 0     15280     15280 
yellow website            5 1      12 0     12631     12631 
yellow agg_analysis       5 1       5 0      5804      5804 
yellow v2                 5 1       2 0      5410      5410 
yellow v1                 5 1       2 0      5367      5367 
yellow bank               1 1      16 0      4303      4303 
yellow v                  5 1       1 0      2954      2954 
yellow p                  5 1       2 0      2939      2939 
yellow b0001_072320141238 5 1       1 0      2923      2923 
yellow ipaddr             5 1       1 0      2917      2917 
yellow v2a                5 1       1 0      2895      2895 
yellow movies             5 1       1 0      2738      2738 
yellow cars               5 1       0 0      1249      1249 
yellow wavelet2           5 1       0 0       615       615 
----

瞧！管道传递给 `grep` （通过 `-v` 翻转匹配）后，我们得到的就是没有 Marvel 混杂的索引的排序了。

这只是命令行上 `cat` 的灵活性的一个简单示例。当你习惯了使用 `cat` ，你会发现它跟其他所有 *nix 工具一样，加上管道、排序和过滤，好用到疯狂。如果你是系统管理员，永远都是 SSH 到设备上，那么当然要花些时间来熟悉 `cat` API 了。




